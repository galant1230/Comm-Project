
整個流程是：

> 時域語音 → 預加重 → 分幀 → 加窗 → FFT / STFT → Mel 濾波器組 → 取 log → DCT → MFCC 特徵

---

## (1) 預加重 Pre-Emphasis

- 真的語音頻譜會有 **spectral tilt**（高頻比較小，低頻比較大）
- 預加重就是用一個「**一階高通濾波 / 一階差分**」去 **拉高高頻，平衡頻譜**
  - 高頻變化快 → 差分後值大  
  - 低頻變化慢 → 差分後值小
- 從「生理」角度說，是為了補償 **聲帶 + 口腔** 把高頻壓掉的效果

結論：**把高頻補回來，讓頻譜比較平坦，方便後面做分析。**

---

## (2) 分幀 Framing

- 語音是「**非平穩訊號**」，頻率會隨時間變
- 我們要用 FFT 分析頻率，前提是假設這一小段訊號頻率**不要變太多** → 所以要切成一幀一幀

一般：

- 取樣率：`8 kHz` 或 `16 kHz`
- 幀長：`20–40 ms`
- 對應點數：常用 `256` 或 `512` 點  

例：`8 kHz`、`256` 點 → `256 / 8000 ≈ 32 ms`

結論：**把語音切成一小塊一小塊（frame），每一塊近似平穩，才能用 FFT 分析頻譜。**

---

## (3) 加窗 Windowing

- 我們做 STFT 時，每一幀都假設是「**週期延拓的訊號**」
- 但實際上，直接截斷會造成 **幀兩端不連續 → 頻譜洩漏（leakage）**
- 所以在每一幀外面乘一個 **window function（如 Hamming）**  
  讓兩端比較「收斂到 0」，連接幀與幀時比較連續

結論：**加窗是為了減少因為截斷造成的邊界不連續，讓頻譜比較乾淨。**

---

## (4) FFT / STFT

- 每一幀加窗後，做 `N` 點 DFT / FFT → 得到該幀的頻譜（STFT）
- 直接做 DFT 複雜度是 `O(N²)`  
  FFT 把公式拆成奇偶項、畫成「蝴蝶圖」，降成 `O(N log N)`
- 蝴蝶運算：每個小單元做「**1 次乘法 + 2 次加法**」，每一級有 `N/2` 個蝴蝶，總共有 `log₂N` 級

結論：**用 FFT 快速算出每一幀的頻譜，減少計算量。**

---

## (5) Mel Filter Banks 梅爾濾波器組

- 做完 FFT 得到**線性頻率**的頻譜後，我們會丟進一組 **Mel-scale 三角濾波器**
- 一般設定：大概 **40 個三角形 filter**，頻率軸不是等間隔，而是照 **Mel 標度**排
  - 低頻濾波器密 → 因為人耳對低頻比較敏感  
  - 高頻濾波器疏 → 高頻分辨率較差
- Mel 標度就是一個把 **Hz 映到「接近人耳感受」的非線性刻度**，近似 log

三角形 filter 的作用：

- **平滑頻譜、減少細節與諧波（harmonics noise）**
- **強調共振峰（formants）**

結論：**用 Mel 濾波器把頻譜轉換成符合人耳聽覺的頻率刻度，得到每個濾波器的能量。**

---

## (6) 倒譜分析 Cepstrum Analysis

### (a) 先取 log magnitude

- 對 Mel 濾波後得到的能量，先取對數（log power / log magnitude spectrum）

好處：

- 把小能量成分拉高，方便看到被大能量蓋住的周期成分
- 對數轉換會讓某些性質變「加法」，方便後面的分離（**convolution → addition**）

---

### (b) 為什麼叫「倒譜」？

- 語音 `x(t)` 可以看成：**激勵（聲帶） `s(t)` 跟 聲道（口腔） `f(t)` 的卷積**

  - 時域：`x(t) = s(t) * f(t)`  
  - 頻域：`X(f) = S(f) · F(f)`

- `S(f)` 給的是細節（harmonics），`F(f)` 給的是光滑的 **Spectral Envelope（共振峰）**

- 在 log spectrum 中：

  - `log X(f) = log S(f) + log F(f)`

- 對 log spectrum 再做「某種反變換」（IDFT / DCT）  
  → 會把「平滑包絡」與「細節」分散到不同的區域（類似 **低頻 vs 高頻**）

---

### (c) 用 IFFT / DCT 分離成分

- 在純粹的倒譜理論：會對 log spectrum 做 **IDFT → 得到 cepstrum**
  - 低 quefrency 部分：對應 **Spectral Envelope（聲道）**
  - 高 quefrency 部分：對應 **pitch / harmonics（聲帶）**
- 在 MFCC 裡，實務上不是用 IDFT，而是用 **DCT**：
  - 對 Mel 濾波後的 log 能量 `Eₖ` 做 DCT
  - 得到前 `L` 個係數（通常取 12 維）
  - 再加上整體 log 能量（或第 0 階） → 常見是 **13 維**
  
**倒譜分析就是：用 log + 反變換，把「頻譜包絡」和「細節」分開，只留下描述包絡形狀的係數 → 這些係數就是 MFCC。**

---

以 MFCC 來說，一段音檔處理完大概是這樣：

- 一共切成 **T 個 frame**
- 每一個 frame 算出 **D 維 MFCC**（例如 13 / 20 / 40 維）

所以數學上是一個：

> **T × D 的矩陣**（或 **D × T**，看你怎麼排）

畫成圖的時候通常：

- **x 軸：時間（frame index）**
- **y 軸：MFCC 維度 / 係數編號**
- **顏色：那個係數的數值大小**

所以每一塊彩色長條，就是  

某一段樂器聲音的 **MFCC 時間–係數矩陣的可視化**。

---
## 處理方式

### 1️⃣ 未處理

就是 **原始 MFCC 值**，沒有做任何縮放或正規化。

**問題：**

- 不同維度的尺度不同、有偏移（mean ≠ 0）
- 有些係數變化範圍很大
- 對很多 classifier（SVM、NN）不是很友善

---

### 2️⃣ 標準化（對特徵）

對「**每一個 MFCC 維度**」去做 z-score 標準化。

假設第 \(d\) 維 MFCC 所有樣本的值是 \(x_{t,d}\)：

- 計算該維度的平均：\(\mu_d\)
- 計算該維度的標準差：\(\sigma_d\)

新特徵：

$$
\tilde{x}_{t,d} = \frac{x_{t,d} - \mu_d}{\sigma_d}
$$

可以是：

- 在「**整個訓練資料**」上算 \(\mu_d, \sigma_d\)，或
- 在「**單一 utterance**」上算（看 paper 怎麼做）

**效果：**

- 每一維 MFCC → 變成「**零均值、單位變異數**」
- 消掉不同係數之間的「**尺度差異**」
- 圖中比「未處理」準確率高一點（62.65 → 67.9）

---

### 3️⃣ 標準化（對時間）

對「**同一個 frame 裡的所有維度**」做標準化。

也就是對每個時間點 \(t\)：

- 算這一幀所有 MFCC 的平均：\(\mu_t\)
- 算這一幀的標準差：\(\sigma_t\)

再做：

$$
\tilde{x}_{t,d} = \frac{x_{t,d} - \mu_t}{\sigma_t}
$$

所以是「**對每一個 row（時間軸） 做 z-score**」。

**問題在哪：**

- 一幀裡 MFCC 各維之間的「**形狀差異**」其實就是頻譜包絡，超重要
- 把整幀壓成零均值單位變異數，相當於 **把這個 shape 搞得很扁、破壞相對關係**
- 所以圖上辨識率反而掉到 56.17，變更爛

---

### 4️⃣ 正規化

這裡通常指的是：

> 對每一個 **MFCC 維度做 min–max normalization**（縮放到 \([0,1]\) 或 \([-1,1]\)）

例如對第 \(d\) 維，令所有資料中此維的最小、最大值分別為 \(x_d^{\text{min}}, x_d^{\text{max}}\)：

$$
\tilde{x}_{t,d} = \frac{x_{t,d} - x_d^{\text{min}}}{x_d^{\text{max}} - x_d^{\text{min}}}
$$

（也可能是對整幀做 L2-normalize，不過在語音 / 這種圖裡，多半是指「**per-feature min-max**」）

**效果：**

- 每一維被壓到固定範圍、數值穩定
- 很多模型（尤其用 sigmoid / tanh 的 NN）會訓練得比較好
- 這張圖裡正規化效果最好 → **91.32%**

---

### 5️⃣ CMWN / CMVN（倒譜正規化）

名字可能拼成 **CMVN / CMWN**，但大致都是：

> **Cepstral Mean (and Variance) Normalization**  
> 「倒譜均值（與變異數）正規化」

**常見作法：**

對 **每一個 utterance、每一維 MFCC**：

- 算該維在時間上的平均 \(\mu_d\)、或再加上變異數 \(\sigma_d\)
- 做（CMVN）：

$$
\tilde{x}_{t,d} = \frac{x_{t,d} - \mu_d}{\sigma_d}
$$

或只減均值（CMN）：

$$
\tilde{x}_{t,d} = x_{t,d} - \mu_d
$$

**目的：**

- 消除 **通道效應 / 錄音環境 / 麥克風** 帶來的固定偏移
- 讓模型更 robust

這種方法是 **針對「時間軸上的每一維」做處理**，跟前面的「對整個資料集算 z-score」不太一樣。

圖上結果是 **71.09%**，比「只對特徵做標準化」還好，但沒有單純的正規化高（這就看實驗環境了）。
